{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "4af9380c",
      "metadata": {
        "id": "4af9380c"
      },
      "source": [
        "# An Introduction to conformal prediction\n",
        "\n",
        "\n",
        "The aim of this notebook is to implement and better understand split conformal prediction, to understand the strenghts and limits of the guarantees.\n",
        "\n",
        "0. Data Generation\n",
        "1. Split conformal prediction  \n",
        "  1.1. basic score function (absolute value of the residuals)  \n",
        "  1.2. 'advanced' score function (locally weighted)  \n",
        "  1.3. Conformal Quantile Regression (CQR)\n",
        "2. Dependence of the coverage wrt the quality of the model\n",
        "3. The coverage is on average on both the test point and the calibration set"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3ea6358e",
      "metadata": {
        "id": "3ea6358e"
      },
      "source": [
        "# I- Data generation"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "70881655",
      "metadata": {
        "id": "70881655"
      },
      "source": [
        "We begin by generating a toy dataset, in which the data follow the distribution\n",
        "$$\n",
        "X \\sim \\mathrm{Beta}(6,3) \\qquad Y| X \\sim \\cos(X) + (1-\\cos(X))\\mathcal{N}(0,0.5).\n",
        "$$"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2fe6a159-4e31-4ff3-8122-d6f64a701f05",
      "metadata": {
        "id": "2fe6a159-4e31-4ff3-8122-d6f64a701f05"
      },
      "outputs": [],
      "source": [
        "import random\n",
        "import numpy as np\n",
        "import scipy as sp\n",
        "import statsmodels as sm\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "colors_blindness = sns.color_palette(\"colorblind\")\n",
        "color_train = colors_blindness[1]\n",
        "color_cal = colors_blindness[9]\n",
        "color_test = colors_blindness[4]\n",
        "np.random.seed(42)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d82ee3b0-b18e-4224-8fc7-8918b5877ffb",
      "metadata": {
        "id": "d82ee3b0-b18e-4224-8fc7-8918b5877ffb"
      },
      "outputs": [],
      "source": [
        "n_train = 100\n",
        "n_cal = 100\n",
        "n_test = 100\n",
        "x_max, x_min = 0, 6 # For plotting limits\n",
        "\n",
        "def sample_data(n):\n",
        "    \"Sample n data points from the given distribution\"\n",
        "\n",
        "    X = sp.stats.beta.rvs(a=6,b=3,loc=0,scale=6,size=n)\n",
        "\n",
        "    ## Heteroscedastic model\n",
        "    sigma = 0.5\n",
        "    y = np.cos(X) + (1-np.cos(X))*sigma*np.random.normal(size=n)\n",
        "    return X, y\n",
        "\n",
        "X_train, y_train = sample_data(n_train)\n",
        "X_cal, y_cal = sample_data(n_cal)\n",
        "X_test, y_test = sample_data(n_test)\n",
        "X,y = np.vstack((X_train, X_cal, X_test)), np.hstack((y_train, y_cal, y_test))\n",
        "\n",
        "x_max, x_min = np.max(np.vstack((X_train, X_cal, X_test))), np.min(np.vstack((X_train, X_cal, X_test)))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6af55d7a-1bd3-4762-aa0b-93fb1eeb0cdd",
      "metadata": {
        "id": "6af55d7a-1bd3-4762-aa0b-93fb1eeb0cdd"
      },
      "outputs": [],
      "source": [
        "plt.scatter(X,y,marker='.',color='black')\n",
        "plt.xlabel(r'$X$')\n",
        "plt.ylabel(r'$Y$')\n",
        "plt.title('Generated data')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3c8c1c02",
      "metadata": {
        "id": "3c8c1c02"
      },
      "source": [
        "The data are randomly splitted into the train and test"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "68154f7d",
      "metadata": {
        "id": "68154f7d"
      },
      "source": [
        "# II- Split Conformal Prediction\n",
        "## II.1- Regression model\n",
        "\n",
        "\n",
        "We rely on a linear regression with polynomial features to fit the data.\n",
        "\n",
        "**Q1 Complete the following implementation of the linear regression**\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e7a9e9d5-fb61-491f-a924-ccefc1905eea",
      "metadata": {
        "id": "e7a9e9d5-fb61-491f-a924-ccefc1905eea"
      },
      "outputs": [],
      "source": [
        "from sklearn.preprocessing import PolynomialFeatures\n",
        "from sklearn import linear_model\n",
        "\n",
        "\n",
        "poly = PolynomialFeatures(4)\n",
        "Xpoly_test = poly.fit_transform(X_test[:, np.newaxis])\n",
        "Xpoly_train = poly.fit_transform(X_train[:, np.newaxis])\n",
        "Xpoly_cal = poly.fit_transform(X_cal[:, np.newaxis])\n",
        "\n",
        "linear_reg = linear_model.LinearRegression(fit_intercept=False)\n",
        "#TODO LINE"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d6c611a8-3470-433b-a9ee-10e13dfae547",
      "metadata": {
        "id": "d6c611a8-3470-433b-a9ee-10e13dfae547"
      },
      "outputs": [],
      "source": [
        "# Visualization\n",
        "plt.scatter(X_train,y_train,marker='.',color=color_train,label=\"Train\")\n",
        "plt.scatter(X_test,y_test,marker='.',color=color_test,label=\"Test\")\n",
        "plt.scatter(X_cal,y_cal,marker='.',color=color_cal,label=\"Calib\")\n",
        "aux = np.linspace(x_min,x_max,500)\n",
        "auxpoly = poly.fit_transform(aux[:, np.newaxis])\n",
        "plt.plot(aux,linear_reg.predict(auxpoly),color=color_train, label=\"Estimation\")\n",
        "plt.legend()\n",
        "plt.xlabel(r'$X$')\n",
        "plt.ylabel(r'$Y$')\n",
        "plt.title('Model fit on training data')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a6728076",
      "metadata": {
        "id": "a6728076"
      },
      "source": [
        "## II.2- Split Conformal Regression with basic scores"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "52179bd9",
      "metadata": {
        "id": "52179bd9"
      },
      "source": [
        "We begin by implementing the standard split conformal regression method"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "472aa54c",
      "metadata": {
        "id": "472aa54c"
      },
      "outputs": [],
      "source": [
        "alpha = 0.1 # We fix the coverage level for all the methods"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "12bf24ac",
      "metadata": {
        "id": "12bf24ac"
      },
      "source": [
        "**Q2 Complete the following cell to implement split conformal regression with the absolute error scores.**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "94fc0e27",
      "metadata": {
        "id": "94fc0e27"
      },
      "outputs": [],
      "source": [
        "class ConformalRegressor:\n",
        "    def __init__(self, model, alpha):\n",
        "        self.model = model\n",
        "        self.alpha = alpha\n",
        "\n",
        "    def score_function(self, x, y):\n",
        "        raise NotImplementedError(\"Score function must be implemented in subclass.\")\n",
        "\n",
        "    def fit(self, x_cal, y_cal):\n",
        "        score_set =  # TODO OPERAND\n",
        "        self.q_hat =  # TODO OPERAND\n",
        "\n",
        "    def predict(self, x):\n",
        "        \"\"\"\n",
        "        Returns lower and upper bounds of the prediction interval at covariate x\n",
        "        \"\"\"\n",
        "        ## TODO BLOCK\n",
        "\n",
        "        ## END TODO BLOCK\n",
        "        return lower_bound, upper_bound\n",
        "\n",
        "class StandardSCP(ConformalRegressor):\n",
        "    def __init__(self, model, alpha):\n",
        "        super().__init__(model, alpha)\n",
        "\n",
        "    def score_function(self, x, y):\n",
        "         # TODO OPERAND\n",
        "         # TODO OPERAND\n",
        "        return score\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c5098eed",
      "metadata": {
        "id": "c5098eed"
      },
      "outputs": [],
      "source": [
        "standardSCP = StandardSCP(model=linear_reg, alpha=alpha)\n",
        "standardSCP.fit(Xpoly_cal, y_cal)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9e7698ec",
      "metadata": {
        "id": "9e7698ec"
      },
      "source": [
        "Let's plot the resulting calibrated prediction interval."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "29c8e3ba",
      "metadata": {
        "id": "29c8e3ba"
      },
      "outputs": [],
      "source": [
        "aux = np.linspace(x_min,x_max,500)\n",
        "auxpoly = poly.fit_transform(aux[:, np.newaxis])\n",
        "lower_scp, upper_scp = standardSCP.predict(auxpoly)\n",
        "\n",
        "\n",
        "plt.fill_between(aux, lower_scp, upper_scp, color=color_cal, alpha=0.3, label='SCP Interval')\n",
        "plt.plot(aux, linear_reg.predict(auxpoly), color=color_train, label='Model Prediction')\n",
        "plt.scatter(X_train, y_train, marker='.', color=color_train, label='Train Data')\n",
        "plt.scatter(X_test, y_test, marker='.', color=color_test, label='Test Data')\n",
        "plt.scatter(X_cal,y_cal,marker='.', color=color_cal, label='Cal Data')\n",
        "plt.xlabel(r'$X$')\n",
        "plt.ylabel(r'$Y$')\n",
        "plt.title('Standard SCP Intervals')\n",
        "plt.legend()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "58330053",
      "metadata": {
        "id": "58330053"
      },
      "source": [
        "As we see, the interval lengths are independent of the covariate $X$. Thus, it can never capture the heteroskedasticity of the data."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f1a535aa",
      "metadata": {
        "id": "f1a535aa"
      },
      "source": [
        "## II.3- Locally Weighted Conformal Regression\n",
        "\n",
        "Locally weighter conformal regression, studied for instance in [Lei et al (2018)](https://arxiv.org/pdf/1604.04173) p30 relies on both a regression model $\\hat{\\mu}(X)$, fitted on the training set, and an a model of the dispersion of the data $\\hat{\\sigma}(X)$, typically an estimate of the conditional mean absolute deviation (MAD) $\\hat{\\sigma}(X) \\approx E[|Y - \\hat{\\mu}(x)| X]$, which is also fitted on the training set.\n",
        "\n",
        "In this paradigm, the scores are adjusted by scaling it by $\\hat{\\sigma}(X)$:\n",
        "\n",
        "$$R_i = \\frac{|Y_i - \\hat{\\mu}(X_i)|}{\\hat{\\sigma(X_i)}}.$$\n",
        "\n",
        "**Q3 Implement the Locally Weighted SCP Class, then fit a MAD (mean absolute deviation) model to the residual and fit the locally-weighted SCP method.**\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cd7f1d97",
      "metadata": {
        "id": "cd7f1d97"
      },
      "outputs": [],
      "source": [
        "class LocallyWeightedSCP(ConformalRegressor):\n",
        "    def __init__(self, model, model_mad, alpha):\n",
        "        super().__init__(model, alpha)\n",
        "        self.model_mad = model_mad\n",
        "\n",
        "    def score_function(self, x, y):\n",
        "\n",
        "        ### TODO BLOCK\n",
        "\n",
        "        ### END TODO BLOCK\n",
        "        return score\n",
        "\n",
        "    def predict(self, x):\n",
        "        ### TODO BLOCK\n",
        "\n",
        "        ### END TODO BLOCK\n",
        "        return lower_bound, upper_bound"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "99c42c1b",
      "metadata": {
        "id": "99c42c1b"
      },
      "outputs": [],
      "source": [
        "# Estimation of the MAD with a Linear Regression on the residuals\n",
        "\n",
        "mad_model = linear_model.LinearRegression(fit_intercept=False) # TODO OPERAND\n",
        "residuals_train = np.abs(y_train - linear_reg.predict(Xpoly_train)) # TODO OPERAND\n",
        "mad_model.fit(Xpoly_train, residuals_train)\n",
        "\n",
        "weightedSCP = LocallyWeightedSCP(model=linear_reg, model_mad=mad_model, alpha=alpha) # TODO OPERAND\n",
        "weightedSCP.fit(Xpoly_cal, y_cal)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9ae3e48d",
      "metadata": {
        "id": "9ae3e48d"
      },
      "outputs": [],
      "source": [
        "# plotting the results\n",
        "\n",
        "aux = np.linspace(x_min,x_max,500)\n",
        "auxpoly = poly.fit_transform(aux[:, np.newaxis])\n",
        "lower_lw_scp, upper_lw_scp = weightedSCP.predict(auxpoly)\n",
        "\n",
        "\n",
        "plt.fill_between(aux, lower_lw_scp, upper_lw_scp, color=color_cal, alpha=0.3, label='lw-SCP Interval')\n",
        "plt.plot(aux, linear_reg.predict(auxpoly), color=color_train, label='Model Prediction')\n",
        "plt.scatter(X_train, y_train, marker='.', color=color_train, label='Train Data')\n",
        "plt.scatter(X_test, y_test, marker='.', color=color_test, label='Test Data')\n",
        "plt.scatter(X_cal, y_cal,marker='.', color=color_cal, label='Cal Data')\n",
        "plt.xlabel(r'$X$')\n",
        "plt.ylabel(r'$Y$')\n",
        "plt.title('Locally weighted SCP Intervals')\n",
        "plt.legend()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "83ab22db",
      "metadata": {
        "id": "83ab22db"
      },
      "source": [
        "As highlighted in [Romano et al (2019)](https://proceedings.neurips.cc/paper_files/paper/2019/file/5103c3584b063c431bd1268e9b5e76fb-Paper.pdf), training the estimating the MAD on the training set leads to a biased estimate,\n",
        "\n",
        "Note, however, that since the MAD estimates are usually fit on the train residual, this gives a biased estimate which underestimates the error, which is compensated by on the train residual, this gives a biased estimate which under-estimate the error, which is compensated by the overly inflating the quantile of the score. Eventually, this leads generally to a less adaptive method than CQR."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "83f50c1a",
      "metadata": {
        "id": "83f50c1a"
      },
      "source": [
        "## II.4- Conformal Quantile Regression (CQR)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6873b4da",
      "metadata": {
        "id": "6873b4da"
      },
      "source": [
        "CQR on the contrary relies on two model of the $1-\\alpha/2$ and $\\alpha$ quantile of the distribution, trained on the training set.\n",
        "\n",
        "**Q4 Complete the following code to implement CQR, then fit it on the training and calibration set.**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e17f343f",
      "metadata": {
        "id": "e17f343f"
      },
      "outputs": [],
      "source": [
        "\n",
        "class ConformalQuantileRegressor(ConformalRegressor):\n",
        "    def __init__(self, model_up, model_down, alpha):\n",
        "        self.model_up = model_up\n",
        "        self.model_down = model_down\n",
        "        self.alpha = alpha\n",
        "\n",
        "    def score_function(self, x, y):\n",
        "        ### TODO BLOCK\n",
        "\n",
        "        ### END TODO BLOCK\n",
        "        return score\n",
        "\n",
        "    def predict(self, x):\n",
        "        ### TODO BLOCK\n",
        "\n",
        "        ### END TODO BLOCK\n",
        "        return lower_bound, upper_bound\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b16d5443",
      "metadata": {
        "id": "b16d5443"
      },
      "outputs": [],
      "source": [
        "from sklearn.utils.fixes import sp_version, parse_version\n",
        "\n",
        "## a good idea is to update scipy (!) to avoid problem of convergence\n",
        "solver = \"highs\" if sp_version >= parse_version(\"1.6.0\") else \"interior-point\"\n",
        "\n",
        "beta = alpha/2\n",
        "qr_down = linear_model.QuantileRegressor(quantile=beta, alpha=0.0, solver='highs')\n",
        "qr_up = linear_model.QuantileRegressor(quantile=1-beta, alpha=0.0, solver='highs')\n",
        "\n",
        "# Fit Upper and Lower Quantile regression\n",
        " #TODO LINE\n",
        " #TODO LINE\n",
        "\n",
        "# Fit the conformal model on the calibration set\n",
        "conformalQR =  # TODO OPERAND\n",
        "conformalQR.fit(Xpoly_cal, y_cal)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b2121dae",
      "metadata": {
        "id": "b2121dae"
      },
      "outputs": [],
      "source": [
        "# plotting the results\n",
        "\n",
        "aux = np.linspace(x_min,x_max,500)\n",
        "auxpoly = poly.fit_transform(aux[:, np.newaxis])\n",
        "lower_cqr, upper_cqr = conformalQR.predict(auxpoly)\n",
        "non_void = upper_cqr>lower_cqr # We check that when lower bound is less than the upper bound, otherwise the interval is empty\n",
        "\n",
        "\n",
        "plt.fill_between(aux[non_void], lower_cqr[non_void], upper_cqr[non_void], color=color_cal, alpha=0.3, label='CQR Interval')\n",
        "plt.plot(aux,qr_up.predict(auxpoly),'--',color=color_train,label=\"model q sup\")\n",
        "plt.plot(aux,qr_down.predict(auxpoly),'--',color=color_train,label=\"model q inf\")\n",
        "plt.scatter(X_train, y_train, marker='.', color=color_train, label='Train Data')\n",
        "plt.scatter(X_test, y_test, marker='.', color=color_test, label='Test Data')\n",
        "plt.scatter(X_cal, y_cal,marker='.', color=color_cal, label='Cal Data')\n",
        "plt.xlabel(r'$X$')\n",
        "plt.ylabel(r'$Y$')\n",
        "plt.title('CQR Intervals')\n",
        "plt.legend()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8e243b71",
      "metadata": {
        "id": "8e243b71"
      },
      "source": [
        "# III- Estimation of the coverage\n",
        "## III.1 - Do we have $P(Y_{n+1}\\in \\hat{C}_{\\alpha}(X_{n+1})) \\ge 1-\\alpha$ ?\n",
        "\n",
        "**Q. Estimate $P(Y_{n+1}\\in \\hat{C}_{\\alpha}(X_{n+1}))$ for the three implemented methods, with asymptotic confidence interval**"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "664206de",
      "metadata": {
        "id": "664206de"
      },
      "source": [
        "Note that you can use the function 'sample_data' to generate fresh new samples."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ef1f5a87",
      "metadata": {
        "id": "ef1f5a87"
      },
      "outputs": [],
      "source": [
        "# TODO CELL\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "17e56af0",
      "metadata": {
        "id": "17e56af0"
      },
      "source": [
        "## III.2- Fool's estimator\n",
        "\n",
        "**Q Which quantity does the following code estimate ?**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "164ddf7c-ec3b-4d93-aca3-d7390f8f94f5",
      "metadata": {
        "id": "164ddf7c-ec3b-4d93-aca3-d7390f8f94f5"
      },
      "outputs": [],
      "source": [
        "n_cal, n_test = 100,10000\n",
        "\n",
        "X_cal_sim, y_cal_sim = sample_data(n_cal)\n",
        "X_test_sim, y_test_sim = sample_data(n_test)\n",
        "\n",
        "Xpoly_cal_sim = poly.transform(X_cal_sim[:, np.newaxis])\n",
        "Xpoly_test_sim = poly.transform(X_test_sim[:, np.newaxis])\n",
        "\n",
        "standardSCP.fit(Xpoly_cal_sim, y_cal_sim)\n",
        "weightedSCP.fit(Xpoly_cal_sim, y_cal_sim)\n",
        "conformalQR.fit(Xpoly_cal_sim, y_cal_sim)\n",
        "\n",
        "lower_scp, upper_scp = standardSCP.predict(Xpoly_test_sim)\n",
        "lower_lw_scp, upper_lw_scp = weightedSCP.predict(Xpoly_test_sim)\n",
        "lower_cqr, upper_cqr = conformalQR.predict(Xpoly_test_sim)\n",
        "\n",
        "coverage_scp = ((lower_scp<=y_test_sim)*(y_test_sim<=upper_scp))\n",
        "coverage_lw_scp = ((lower_lw_scp<=y_test_sim)*(y_test_sim<=upper_lw_scp))\n",
        "coverage_cqr = ((lower_cqr<=y_test_sim)*(y_test_sim<=upper_cqr))\n",
        "\n",
        "# Print coverages\n",
        "print(\"Theoretical coverage: \",1-alpha)\n",
        "print(f\"Empirical coverage SCP: {np.mean(coverage_scp)} +/- {1.96*np.std(coverage_scp,ddof=1)/np.sqrt(n_test)} (IC 95%)\")\n",
        "print(f\"Empirical coverage lw-SCP: {np.mean(coverage_lw_scp)} +/- {1.96*np.std(coverage_lw_scp,ddof=1)/np.sqrt(n_test)} (IC 95%)\")\n",
        "print(f\"Empirical coverage CQR: {np.mean(coverage_cqr)} +/- {1.96*np.std(coverage_cqr,ddof=1)/np.sqrt(n_test)} (IC 95%)\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1b9fcf6a",
      "metadata": {
        "id": "1b9fcf6a"
      },
      "source": [
        "## III.3 Distribution of the coverage conditionnal to the calibration set"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b5725dc0",
      "metadata": {
        "id": "b5725dc0"
      },
      "source": [
        "Actually, what was previously estimated is\n",
        "$$\n",
        "P(Y_{n+1}\\in \\hat{C}_{\\alpha}(X_{n+1})|(X_i,Y_i)_{i\\in [n]}),\n",
        "$$\n",
        "which is not always greater that $1-\\alpha$ !\n",
        "\n",
        "Interestingly, as explained for instance in [[Angelopoulos et al.]]((https://arxiv.org/pdf/2107.07511)), this conditionnal distribution actually follows a well-known distribution:\n",
        "$$\n",
        "P(Y_{n+1}\\in \\hat{C}_{\\alpha}(X_{n+1})|(X_i,Y_i)_{i\\in [n]}) \\sim Beta(k_{\\alpha},n+1 - k_{\\alpha}),\n",
        "$$\n",
        "with $k_{\\alpha} = \\lceil{(1-\\alpha)(n+1)}\\rceil$\n",
        "\n",
        "**Q. Illustrate the distribution of the coverage conditionally on the calibration set, then see how it evolves with the size of the calibration set. Check that it matches the theory**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d2a757b6",
      "metadata": {
        "id": "d2a757b6"
      },
      "outputs": [],
      "source": [
        "def coverage_conditional_on_cal(n_cal, n_test, n_sim):\n",
        "    \"\"\"\n",
        "    Sample n_sim calibration sets, for each, estimate the conditional coverage\n",
        "    using a monte-carlo estimation with n_test samples.\n",
        "    \"\"\"\n",
        "    coverage_scp = np.zeros(n_sim)\n",
        "    coverage_lw_scp = np.zeros(n_sim)\n",
        "    coverage_cqr = np.zeros(n_sim)\n",
        "    # TODO BLOCK\n",
        "\n",
        "\n",
        "    # END TODO BLOCK\n",
        "    return coverage_scp, coverage_lw_scp, coverage_cqr\n",
        "\n",
        "n_sim = 5000\n",
        "n_cal = 100\n",
        "n_test = 20*n_cal\n",
        "coverage_scp, coverage_lw_scp, coverage_cqr = coverage_conditional_on_cal(n_cal, n_test, n_sim)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0adf7f6c",
      "metadata": {
        "id": "0adf7f6c"
      },
      "outputs": [],
      "source": [
        "# Plotting the results, and comparing it to the theoretical density\n",
        "\n",
        "bins = int(n_sim**(1/3)*2)\n",
        "x_min_cov,x_max_cov=np.min(coverage_cqr), np.max(coverage_cqr)\n",
        "aux_x = np.linspace(x_min_cov,x_max_cov,500)\n",
        "\n",
        "k_alpha =np.ceil((1-alpha)*(n_cal+1))\n",
        "density_th = sp.stats.beta.pdf(aux_x, a=k_alpha, b=n_cal+1 - k_alpha)\n",
        "\n",
        "\n",
        "plt.plot(aux_x,density_th, color='red',label='Theoretical density')\n",
        "plt.hist(coverage_scp, bins=bins, label='SCP', alpha =0.3, density=True)\n",
        "plt.hist(coverage_lw_scp, bins=bins, label='lw-SCP', alpha =0.3, density=True)\n",
        "plt.hist(coverage_cqr, bins=bins, label='CQR', alpha =0.3, density=True)\n",
        "plt.axvline(x=1-alpha, color='black', linestyle='--', label='Theoretical Coverage')\n",
        "plt.xlabel('Empirical Coverage')\n",
        "plt.legend()\n",
        "plt.title('Coverage conditional on the calibration set distribution')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "427f0e20",
      "metadata": {
        "id": "427f0e20"
      },
      "source": [
        "### What is happening when we increase/decrease the number of n_cal ?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "de36c90e",
      "metadata": {
        "id": "de36c90e"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "Hf8UHxiD4v1z",
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "Hf8UHxiD4v1z"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2OMv7wuO5RSF",
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "2OMv7wuO5RSF"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "robdec",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}